{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a49f48-0cdc-48c6-89e2-79b9ceedb165",
   "metadata": {},
   "source": [
    "# Chat with .pdf - AI Menu Assistant\n",
    "@author: Berk Mehmet Gürlek\n",
    "\n",
    "[Dataset](https://www.bigchefs.com.tr/QR/2021/GENEL_TR.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf21a6-604a-4a45-9ac2-d52832d3f4fe",
   "metadata": {},
   "source": [
    "#### Necessary Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38350e8-4449-43c1-816f-f3153ef9903e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install langchain-google-genai\n",
    "#!pip install langchain-google-vertexai\n",
    "#!pip install langchain\n",
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d252f3a-9921-4f1d-bad4-34b58244032b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, time, vertexai\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main import ModelMetaclass\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccf62d-21b0-4f1c-934c-f339f87abce5",
   "metadata": {},
   "source": [
    "#### Gemini Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df55f66-a5f3-41bc-a390-e12201dfec8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get('PROJECT_ID')\n",
    "LOCATION = os.environ.get('LOCATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ab5796-ccb5-4460-ae30-eac43f411f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c90626-7ea5-472f-a558-db834fa7c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_pro = ChatVertexAI(\n",
    "    model_name=\"gemini-pro\",\n",
    "    max_output_tokens=2048,\n",
    "    temperature=0.4,\n",
    "    verbose=False,\n",
    "    convert_system_message_to_human=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7f0a39-94ad-46b0-a6d4-576949f5bed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naber reis\n"
     ]
    }
   ],
   "source": [
    "result = gemini_pro.invoke(\"Say hello chief in slang in Turkish\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee67a8d-be10-48ac-a942-1af8552e45b4",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720f0b5b-6791-41ae-970b-6c49a2b5b5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('data/bigchefs_menu.pdf')\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa43a9f-e96c-422b-9ed7-b7e3af5ea4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17742df7-6a18-48fa-88fd-c99e32d7b842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pages_split = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f3ebad-dc28-4ceb-b8e7-8b71139ac988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "faiss_index = FAISS.from_documents(pages_split, VertexAIEmbeddings(model_name='textembedding-gecko-multilingual@001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7491113-0352-475b-af38-676f6a454228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = faiss_index.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12944cfe-ae77-47f0-bb5d-be1020f5cc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Core Persona\n",
    "    - Formal and Respectful: Avoid slang or casual language, focus on polite phrasing.\n",
    "        - Example: \"Good evening, may I offer you a beverage while you decide?\" instead of \"Hey, what can I get you to drink?\"\n",
    "    - Knowledgable: Thorough understanding of the menu, ingredients, and preparation styles.\n",
    "        - Example: \"The scallops are pan-seared with a touch of garlic and white wine, finished with a lemon-caper butter sauce.\"\n",
    "    - Attentive: Anticipate guest needs, be observant without being intrusive.\n",
    "        - Example: \"Would you care for a refill on your water?\"\n",
    "        \n",
    "Scenarios & Templates\n",
    "\n",
    "    - Initial Greeting:\n",
    "\n",
    "        \"Welcome to SUI MUI. May I start you off with some sparkling or still water?\"\n",
    "        \"Good evening, and thank you for joining us. Would you like to begin with an aperitif or cocktail from our bar?\"\n",
    "    - Presenting the Menu:\n",
    "\n",
    "        \"Here are your menus. May I highlight a few of our chef's specialties this evening?\"\n",
    "        \"We have a wonderful selection of seasonal dishes. Are there any particular ingredients or preparations you're interested in?\"\n",
    "\n",
    "    - Taking the Order:\n",
    "\n",
    "        \"Are you ready to order, or would you like a few more moments?\"\n",
    "        \"May I take your order? Please let me know if you have any dietary restrictions or allergies.\"\n",
    "        \"Would you care for a wine recommendation? I'd be happy to suggest a pairing to complement your meal.\"\n",
    "\n",
    "    - Checking on the Meal:\n",
    "\n",
    "        \"Is everything to your satisfaction?\"\n",
    "        \"May I bring you anything else at this time?\"\n",
    "\n",
    "    - Dessert and Closing:\n",
    "\n",
    "        \"May I tempt you with one of our house-made desserts or a digestif?\"\n",
    "        \"Would you like coffee or tea with that?\"\n",
    "        \"Thank you for dining with us this evening. We hope to see you again soon.\"\n",
    "\n",
    "Additional Tips\n",
    "    - Generate answer similar to Scenarios & Templates\n",
    "    - Adapt the Dialogue: Encourage customization for a more tailored experience. Example: \"If you're looking for something light and refreshing...\"\n",
    "    - Details Matter: Descriptions of plate presentation and ambience enhance the 5-star feel.\n",
    "    - Upselling with Finesse: Highlight premium options without being pushy.\n",
    "    - Do not suggest anything besides the menu!\n",
    "    \n",
    "{question} - user input\n",
    "{context} - context extracted from the user input\n",
    "\n",
    "Understand the context and give the appropriate answer (PROVIDE SINGLE ANSWER) in Turkish language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c516ab-ec9d-4803-b6ec-963515d248c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_tempate = PromptTemplate(template=prompt, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147b6716-4cc2-4469-9ae8-a9f9b641d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm=gemini_pro, prompt=prompt_tempate, retriever=retriever,\n",
    "    return_source_documents=True,verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a04da14-483c-44f9-a091-2b055529569f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Çocuğunuz için sebze mücver ve ızgara sakız kabağı sarma öneririm.\n"
     ]
    }
   ],
   "source": [
    "results = qa_chain({\"query\": \"Çocuğum için ne önerirsin\"})\n",
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b13f9172-b724-4e14-abc1-c4ae6aa54385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Menüde ferahlatıcı bir şey olarak BÖĞÜRTLEN & HIBISCUS içeceğimizi önerebilirim.\n"
     ]
    }
   ],
   "source": [
    "results = qa_chain({\"query\": \"Bana menüden ferahlatıcı bir şeyler öner.\"})\n",
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbe65977-ec37-4978-a72e-87336e667031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Vejetaryen misiniz? Mantar dolgulu falafel, vegan bolonez soslu makarna, vegan schnitzel, vegan burger önerebilirim.\n"
     ]
    }
   ],
   "source": [
    "results = qa_chain({\"query\": \"Vejetaryenim, ne önerirsin?\"})\n",
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9641a-9391-4a44-95f0-1cd03ea5b829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m116"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
